{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "%matplotlib inline"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "\n# Customize resampling target\n\nThis example demonstrates how to customize the resampling target to achieve advanced resampling control.\nThis can be easily done by setting the \"target_label\" and \"n_target_samples\" parameter when calling the \"fit()\" method. \n\nNote that this feature only applies to resampling-based ensemble classifiers that are iteratively trained.\n\nThis example uses:\n\n    - :class:`imbalanced_ensemble.ensemble.SelfPacedEnsembleClassifier`\n    - :class:`imbalanced_ensemble.ensemble.SMOTEBoostClassifier`\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "# Authors: Zhining Liu <zhining.liu@outlook.com>\n# License: MIT"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "print(__doc__)\n\n# Import imbalanced_ensemble\nimport imbalanced_ensemble as imbens\n\n# Import utilities\nfrom sklearn.datasets import make_classification\nfrom sklearn.model_selection import train_test_split\nfrom imbalanced_ensemble.ensemble.base import sort_dict_by_key\nfrom collections import Counter\n\n# Import plot utilities\nfrom imbalanced_ensemble.utils._plot import set_ax_border\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nsns.set_context('talk')\n\nRANDOM_STATE = 42\n\ninit_kwargs = {\n    'n_estimators': 1,\n    'random_state': RANDOM_STATE,\n}\nfit_kwargs = {\n    'train_verbose': {\n        'print_metrics': False,\n    },\n}\n\n# sphinx_gallery_thumbnail_number = -1"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Prepare data\nMake a toy 3-class imbalanced classification task.\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "# Generate and split a synthetic dataset\nX, y = make_classification(n_classes=3, n_samples=2000, class_sep=2,\n    weights=[0.1, 0.3, 0.6], n_informative=3, n_redundant=1, flip_y=0,\n    n_features=20, n_clusters_per_class=2, random_state=RANDOM_STATE)\nX_train, X_valid, y_train, y_valid = train_test_split(X, y, \n    test_size=0.5, stratify=y, random_state=RANDOM_STATE)\n\n# Print class distribution\nprint('Training dataset distribution    %s' % sort_dict_by_key(Counter(y_train)))\nprint('Validation dataset distribution  %s' % sort_dict_by_key(Counter(y_valid)))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Implement some plot utilities\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "ylim = (0, 630)\n\nall_distribution = {}\n\ndef plot_class_distribution(distr:dict, xlabel:str='Class Label', \n                            ylabel:str='Number of samples', **kwargs):\n    distr = dict(sorted(distr.items(), key=lambda k: k[0], reverse=True))\n    ax = sns.barplot(\n        x=list(distr.keys()), \n        y=list(distr.values()),\n        order=list(distr.keys()),\n        **kwargs\n    )\n    set_ax_border(ax)\n    ax.grid(axis='y', alpha=0.5, ls='-.')\n    ax.set_xlabel(xlabel)\n    ax.set_ylabel(ylabel)\n    return ax\n\ndef plot_class_distribution_comparison(clf, \n                                       title1='Original imbalanced class distribution', \n                                       title2='After resampling', figsize=(12, 6)):\n    fig, (ax1, ax2) = plt.subplots(1, 2, figsize=figsize)\n    plot_class_distribution(clf.origin_distr_, ax=ax1)\n    ax1.set(ylim=ylim, title=title1)\n    plot_class_distribution(clf.target_distr_, ax=ax2)\n    ax2.set(ylim=ylim, title=title2)\n    fig.tight_layout()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Default under-sampling\nBy default, under-sampling-based ensemble methods will consider the smallest class as the minority class (class 0 with 100 samples).  \nAll other classes (class 1 and 2) will be considered as majority classes and will be under-sampled until the number of samples is equalized.  \n\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Take ``SelfPacedEnsembleClassifier`` as example\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "spe_clf = imbens.ensemble.SelfPacedEnsembleClassifier(**init_kwargs)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "**Train with the default under-sampling setting**\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "spe_clf.fit(X_train, y_train, **fit_kwargs)\n\nall_distribution['Before under-sampling'] = spe_clf.origin_distr_\nresampling_type='After default under-sampling'\nall_distribution[resampling_type] = spe_clf.target_distr_\nplot_class_distribution_comparison(spe_clf, title2=resampling_type)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Specify the class targeted by the under-sampling\n**Set parameter ``target_label``: int**  \nAll other classes that have more samples than the target class will be considered as majority classes.  \nThey will be under-sampled until the number of samples is equalized.  \nThe remaining minority classes (if any) will stay unchanged.\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "spe_clf.fit(X_train, y_train, \n            target_label=1, # target class 1\n            **fit_kwargs)\n\nresampling_type='After under-sampling (target class 1)'\nall_distribution[resampling_type] = spe_clf.target_distr_\nplot_class_distribution_comparison(spe_clf, title2=resampling_type)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Specify the desired number of samples after under-sampling\n**Set parameter ``n_target_samples``: int or dict**  \nIf int, all classes that have more than the n_target_samples samples will be under-sampled until the number of samples is equalized.\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "spe_clf.fit(X_train, y_train, \n            n_target_samples=200, # target number of samples 200\n            **fit_kwargs)\n\nresampling_type='After under-sampling (target number 200)'\nall_distribution[resampling_type] = spe_clf.target_distr_\nplot_class_distribution_comparison(spe_clf, title2=resampling_type)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Specify the desired number of samples of each class after under-sampling\n**Set parameter ``n_target_samples``: int or dict**  \nIf dict, the keys correspond to the targeted classes. The values correspond to the desired number of samples for each targeted class.\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "spe_clf.fit(X_train, y_train, \n            n_target_samples={\n                0: 80,\n                1: 200,\n                2: 400,\n            }, # target number of samples\n            **fit_kwargs)\n\nresampling_type='After under-sampling \\n(target number {0: 80, 1: 200, 2: 400})'\nall_distribution[resampling_type] = spe_clf.target_distr_\nplot_class_distribution_comparison(spe_clf, title2=resampling_type)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Over-sampling\nBy default, over-sampling-based ensemble methods will consider the largest class as the majority class (class 2 with 600 samples).  \nAll other classes (class 0 and 1) will be considered as minority classes and will be over-sampled until the number of samples is equalized.\n\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "**The over-sampling schedule can be customized in the same way as under-sampling.**\n\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Take ``SMOTEBoostClassifier`` as example\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "smoteboost_clf = imbens.ensemble.SMOTEBoostClassifier(**init_kwargs)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "**Train with the default under-sampling setting**\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "smoteboost_clf.fit(X_train, y_train, **fit_kwargs)\n\nall_distribution['Before over-sampling'] = smoteboost_clf.origin_distr_\nresampling_type='After default over-sampling'\nall_distribution[resampling_type] = smoteboost_clf.target_distr_\nplot_class_distribution_comparison(smoteboost_clf, title2=resampling_type)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "**Specify the class targeted by the over-sampling**\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "smoteboost_clf.fit(X_train, y_train, \n                   target_label=1, # target class 1\n                   **fit_kwargs)\n\nresampling_type='After over-sampling (target class 1)'\nall_distribution[resampling_type] = smoteboost_clf.target_distr_\nplot_class_distribution_comparison(smoteboost_clf, title2=resampling_type)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "**Specify the desired number of samples after over-sampling**\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "smoteboost_clf.fit(X_train, y_train, \n                   n_target_samples=400, # target number of samples 400\n                   **fit_kwargs)\n\nresampling_type='After over-sampling (target number 400)'\nall_distribution[resampling_type] = smoteboost_clf.target_distr_\nplot_class_distribution_comparison(smoteboost_clf, title2=resampling_type)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "**Specify the desired number of samples of each class after over-sampling**\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "smoteboost_clf.fit(X_train, y_train, \n                   n_target_samples={\n                       0: 200,\n                       1: 400,\n                       2: 600,\n                   }, # target number of samples\n                   **fit_kwargs)\n\nresampling_type='After over-sampling \\n(target number {0: 200, 1: 400, 2: 600})'\nall_distribution[resampling_type] = smoteboost_clf.target_distr_\nplot_class_distribution_comparison(smoteboost_clf, title2=resampling_type)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Visualize different resampling target\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "sns.set_context('notebook')\nfig, axes = plt.subplots(2, 5, figsize=(20, 8))\nfor ax, title in zip(axes.flatten(), list(all_distribution.keys())):\n    plot_class_distribution(all_distribution[title], ax=ax, palette=\"Blues_d\")\n    ax.set(ylim=ylim, title=title)\nfig.tight_layout()"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.13"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}