{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "%matplotlib inline"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "\n# Train and predict with an ensemble classifier\n\nThis example shows the basic usage of an \n:mod:`imbalanced_ensemble.ensemble` classifier.\n\nThis example uses:\n\n    - :class:`imbalanced_ensemble.ensemble.SelfPacedEnsembleClassifier`\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "# Authors: Zhining Liu <zhining.liu@outlook.com>\n# License: MIT"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "print(__doc__)\n\n# Import imbalanced_ensemble\nimport imbalanced_ensemble as imbens\n\n# Import utilities\nfrom collections import Counter\nimport sklearn\nfrom sklearn.datasets import make_classification\nfrom sklearn.model_selection import train_test_split\nfrom imbalanced_ensemble.ensemble.base import sort_dict_by_key\n\n# Import plot utilities\nimport matplotlib.pyplot as plt\nfrom imbalanced_ensemble.utils._plot import plot_2Dprojection_and_cardinality\n\nRANDOM_STATE = 42"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Prepare & visualize the data\nMake a toy 3-class imbalanced classification task.\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "# Generate and split a synthetic dataset\nX, y = make_classification(n_classes=3, n_samples=2000, class_sep=2,\n    weights=[0.1, 0.3, 0.6], n_informative=3, n_redundant=1, flip_y=0,\n    n_features=20, n_clusters_per_class=2, random_state=RANDOM_STATE)\nX_train, X_valid, y_train, y_valid = train_test_split(X, y, \n    test_size=0.5, stratify=y, random_state=RANDOM_STATE)\n\n# Visualize the training dataset\nfig = plot_2Dprojection_and_cardinality(X_train, y_train, figsize=(8, 4))\nplt.show()\n\n# Print class distribution\nprint('Training dataset distribution    %s' % sort_dict_by_key(Counter(y_train)))\nprint('Validation dataset distribution  %s' % sort_dict_by_key(Counter(y_valid)))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Using ensemble classifiers in ``imbalanced_ensemble``\nTake ``SelfPacedEnsembleClassifier`` as example\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "# Initialize an SelfPacedEnsembleClassifier\nclf = imbens.ensemble.SelfPacedEnsembleClassifier(random_state=RANDOM_STATE)\n\n# Train an SelfPacedEnsembleClassifier\nclf.fit(X_train, y_train)\n\n# Make predictions\ny_pred_proba = clf.predict_proba(X_valid)\ny_pred = clf.predict(X_valid)\n\n# Evaluate\nbalanced_acc_score = sklearn.metrics.balanced_accuracy_score(y_valid, y_pred)\nprint (f'SPE: ensemble of {clf.n_estimators} {clf.base_estimator_}')\nprint ('Validation Balanced Accuracy: {:.3f}'.format(balanced_acc_score))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Set the ensemble size\n(parameter ``n_estimators``: int)\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "from imbalanced_ensemble.ensemble import SelfPacedEnsembleClassifier as SPE\nfrom sklearn.metrics import balanced_accuracy_score\n\nclf = SPE(\n    n_estimators=5, # Set ensemble size to 5\n    random_state=RANDOM_STATE,\n).fit(X_train, y_train)\n\n# Evaluate\nbalanced_acc_score = balanced_accuracy_score(y_valid, clf.predict(X_valid))\nprint (f'SPE: ensemble of {clf.n_estimators} {clf.base_estimator_}')\nprint ('Validation Balanced Accuracy: {:.3f}'.format(balanced_acc_score))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Use different base estimator\n(parameter ``base_estimator``: estimator object)\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "from sklearn.svm import SVC\n\nclf = SPE(\n    n_estimators=5,\n    base_estimator=SVC(probability=True), # Use SVM as the base estimator\n    random_state=RANDOM_STATE,\n).fit(X_train, y_train)\n\n# Evaluate\nbalanced_acc_score = balanced_accuracy_score(y_valid, clf.predict(X_valid))\nprint (f'SPE: ensemble of {clf.n_estimators} {clf.base_estimator_}')\nprint ('Validation Balanced Accuracy: {:.3f}'.format(balanced_acc_score))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Enable training log\n(``fit()`` parameter ``train_verbose``: bool, int or dict)\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "clf = SPE(random_state=RANDOM_STATE).fit(\n    X_train, y_train, \n    train_verbose=True, # Enable training log\n)"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.5"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}